from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import re

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®èª­ã¿è¾¼ã¿
model_name = "Mizuiro-sakura/luke-japanese-large-sentiment-analysis-wrime"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ï¼ˆãƒ¢ãƒ‡ãƒ«ã®é †ç•ªé€šã‚Šï¼‰
labels = [
    "joy", "trust", "fear", "surprise", "sadness", "disgust", "anger", "anticipation"
]

# æ–‡ã‚’æ—¥æœ¬èªã§åˆ†å‰²
def split_text_into_sentences(text):
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
    return [s.strip() for s in sentences if s.strip()]

# æ„Ÿæƒ…åˆ†æï¼ˆæ‚²ã—ã¿ãŒã‚ã‚‹å ´åˆã¯å„ªå…ˆã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãï¼‰
def analyze_sentiment(text):
    sentences = split_text_into_sentences(text)
    emotion_scores = {label: 0.0 for label in labels}

    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
            scores = torch.nn.functional.softmax(outputs.logits, dim=1)[0]
            for i, label in enumerate(labels):
                emotion_scores[label] += scores[i].item()

    # ğŸ’¡ ç‰¹å®šã®æ„Ÿæƒ…ãŒä¸€å®šä»¥ä¸Šã‚ã‚‹å ´åˆã¯å„ªå…ˆçš„ã«è¿”ã™
    if emotion_scores["sadness"] > 0.3:
        return "sadness"
    if emotion_scores["anger"] > 0.3:
        return "anger"

    # é€šå¸¸ã¯ã‚¹ã‚³ã‚¢æœ€å¤§ã®æ„Ÿæƒ…ã‚’è¿”ã™
    max_emotion = max(emotion_scores, key=emotion_scores.get)
    return max_emotion
