from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import re

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®èª­ã¿è¾¼ã¿
model_name = "Mizuiro-sakura/luke-japanese-large-sentiment-analysis-wrime"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ï¼ˆãƒ¢ãƒ‡ãƒ«ã®é †ç•ªé€šã‚Šï¼‰
labels = [
    "joy", "trust", "fear", "surprise", "sadness", "disgust", "anger", "anticipation"
]

# æ„Ÿæƒ…ã«å¿œã˜ãŸã²ã¨ã“ã¨ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³
reaction_map = {
    "joy": "æ¥½ã—ãã†ã ã­ï¼âœ¨",
    "trust": "ä¿¡é ¼ã§ãã‚‹æ™‚é–“ã ã£ãŸã®ã‹ãªï¼Ÿ",
    "fear": "ã¡ã‚‡ã£ã¨ä¸å®‰ã ã£ãŸï¼ŸðŸ’­",
    "surprise": "ã³ã£ãã‚Šã—ãŸã“ã¨ãŒã‚ã£ãŸã‚“ã ã­ï¼ðŸ˜²",
    "sadness": "ã‚‚ã—ã‹ã—ã¦ã€ã¤ã‚‰ã‹ã£ãŸï¼ŸðŸ˜¢",
    "disgust": "ã‚¤ãƒ¤ãªæ°—åˆ†ã«ãªã£ã¡ã‚ƒã£ãŸã®ã‹ã‚‚â€¦ðŸ’¦",
    "anger": "ã‚€ã‹ã£ã¨ããŸæ„Ÿã˜â€¦ï¼ŸðŸ’¢",
    "anticipation": "ä½•ã‹æ¥½ã—ã¿ã«ã—ã¦ã‚‹ã®ã‹ãªï¼ŸðŸ˜Œ"
}

# æ–‡ã‚’æ—¥æœ¬èªžã§åˆ†å‰²
def split_text_into_sentences(text):
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
    return [s.strip() for s in sentences if s.strip()]

# æ„Ÿæƒ…åˆ†æžï¼ˆæ„Ÿæƒ…ï¼‹ã²ã¨ã“ã¨ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿”ã™ï¼‰
def analyze_sentiment(text):
    sentences = split_text_into_sentences(text)
    emotion_scores = {label: 0.0 for label in labels}

    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
            scores = torch.nn.functional.softmax(outputs.logits, dim=1)[0]
            for i, label in enumerate(labels):
                emotion_scores[label] += scores[i].item()

    if emotion_scores["sadness"] > 0.3:
        emotion = "sadness"
    elif emotion_scores["anger"] > 0.3:
        emotion = "anger"
    else:
        emotion = max(emotion_scores, key=emotion_scores.get)

    message = reaction_map.get(emotion, "")
    return emotion, message
